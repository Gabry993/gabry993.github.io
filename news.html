<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>News - Gabriele Abbate</title>
  <meta name="description" content="Webpage of Gabriele Abbate">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="/news.html">
  <link rel="shortcut icon" type ="image/x-icon" href="/favicon.ico">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

  <link rel="preconnect" href="https://player.vimeo.com">
  <link rel="preconnect" href="https://i.vimeocdn.com">
  <link rel="preconnect" href="https://f.vimeocdn.com">



<!-- Google Analytics (original) -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');

</script>

<!-- Global site tag (gtag.js) - Google Analytics 4 -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '');
</script>

<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','');</script>
<!-- End Google Tag Manager -->



</head>


  <body>

    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id="
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<nav class="navbar sticky-top navbar-expand-md navbar-dark bg-primary">
    <a class="navbar-brand" href="/">
     <img src="/favicon.ico" width="30" height="30" style="margin-right:5px" class="d-inline-block align-top" alt="">
      Gabriele Abbate
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarColor02">
        <ul class="navbar-nav mr-auto">
        <ul class="navbar-nav">
          <li class="nav-item">
              <a class="nav-link" href="/">Home</a>
          </li> 
          
           <li class="nav-item">
            <a class="nav-link" href="/about">About</a>
           </li> 
          
           <li class="nav-item">
            <a class="nav-link" href="/publications">Publications</a>
           </li> 
          
           <li class="nav-item">
            <a class="nav-link" href="/news">News</a>
           </li> 
          
        </ul>
  </div>
</nav>



    <div class="container-fluid">
      <div class="row">
        <div id="textid" class="col-sm-12">
  <h2 id="news">News</h2>

<div class="jumbotron">

  <!-- <p style="font-size:15px; display:inline">[10/2024]&ensp;</p><p style="font-size:20px; display:inline">Publication at IROS 2024</p> -->
  <p style="font-size:15px; display:inline">[10/2024] - </p>
  <p style="font-size:20px; display:inline">Publication at IROS 2024</p>
  <!-- <h4>10/2024 - Publication at IROS 2024</h4> -->

  <p>Our paper <a href="https://arxiv.org/abs/2410.03287">“A Service Robot in the Wild: Analysis of Users Intentions, Robot Behaviors, and Their Impact on the Interaction”</a> will be published at the 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2024).<br /></p>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/NNgbNRxm5V4?si=RQnvyUaNn1z9tOFu" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

  <!-- <p style="font-size:15px; display:inline">[09/2024]&ensp;</p><p style="font-size:20px; display:inline">We hosted HFR 2024 in Lugano!</p> -->
  <p style="font-size:15px; display:inline">[09/2024] - </p>
  <p style="font-size:20px; display:inline">We hosted HFR 2024 in Lugano!</p>
  <!-- <h4>09/2024 - We hosted HFR 2024 in Lugano!</h4> -->

  <div class="row">
    <div class="col-2">
      <p> <a href="images/HFR_logo.png"><img src="images/HFR_logo.png" width="100%" /></a> </p>
    </div>
    <div class="col-10">
      <p> We organized the 17th International Workshop on Human-Friendly Robotics (HFR 2024) in Lugano. It was a nice opportunity to meet and discuss with members of the HRI community. The workshop featured a rich program of 4 keynote speeches, 4 oral sessions with 19 talks, 2 poster sessions, and 3 technical talks from our sponsors. All accepted papers (including two of ours!) have received at least two reviews and will appear in Springer Proceedings of the 17th International Workshop on Human-Friendly Robotics (HFR2024). <br />Check the program on the <a href="https://sites.google.com/view/hfr2024/home">workshop website</a> to see what it was all about. </p>
    </div>
  </div>
  <p><a href="images/hfr_group.jpeg"><img src="images/hfr_group.jpeg" width="100%" /></a></p>

  <!-- <p style="font-size:15px; display:inline">[08/2024]&ensp;</p><p style="font-size:20px; display:inline">Publications at HFR 2024</p> -->
  <p style="font-size:15px; display:inline">[08/2024] - </p>
  <p style="font-size:20px; display:inline">Publications at HFR 2024</p>
  <!-- <h4>08/2024 - Publications at HFR 2024</h4> -->

  <p>Our two papers, <a href="https://youtu.be/6PiVOs6P4JA">“Learning Hand State Estimation for a Light Exoskeleton”</a> by G. Abbate, A. Giusti, L. Randazzo and A. Paolillo, and “Hearing the Robot’s Mind: Sonification for Explicit Feedback in Human-Robot Interaction” by S. Arreghini, A. Paolillo, G. Abbate and A. Giusti have been accepted at the 17th International Workshop on Human-Friendly Robotics (HFR2024).</p>

  <!-- <p style="font-size:15px; display:inline">[05/2024]&ensp;</p><p style="font-size:20px; display:inline">We were at ICRA 2024 in Yokohama!</p> -->
  <p style="font-size:15px; display:inline">[05/2024] - </p>
  <p style="font-size:20px; display:inline">We were at ICRA 2024 in Yokohama!</p>
  <!-- <h4>05/2024 - We were at ICRA 2024 in Yokohama!</h4> -->

  <p>We joined the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024) which was held in beautiful Yokohama. It was a great opportunity to present our work, get in touch with other researchers and start new collaborations! We also ate a lot of sushi :D<br /> <a href="images/icra2024_crop.jpeg"><img src="images/icra2024_crop.jpeg" width="100%" /></a> </p>

  <!-- <p style="font-size:15px; display:inline">[04/2024]&ensp;</p><p style="font-size:20px; display:inline">Publication at ICRA 2024</p> -->
  <p style="font-size:15px; display:inline">[04/2024] - </p>
  <p style="font-size:20px; display:inline">Publication at ICRA 2024</p>
  <!-- <h4>04/2024 - Publication at ICRA 2024</h4> -->

  <p>Our paper <a href="https://ieeexplore.ieee.org/document/10610289">“Predicting the Intention to Interact with a Service Robot: the Role of Gaze Cues”</a> will be published at the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024).<br /></p>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/5V6efrEtfBI?si=srRksJPn2YSKEEQp" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

  <!-- <p style="font-size:15px; display:inline">[03/2024]&ensp;</p><p style="font-size:20px; display:inline">Publication at HRI 2024</p> -->
  <p style="font-size:15px; display:inline">[03/2024] - </p>
  <p style="font-size:20px; display:inline">Publication at HRI 2024</p>
  <!-- <h4>03/2024 - Publication at HRI 2024</h4> -->

  <p>Our paper <a href="https://dl.acm.org/doi/abs/10.1145/3610977.3637470">“A Long-Range Mutual Gaze Detector for HRI”</a> will be published at the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI 2024).<br /></p>

  <!-- <p style="font-size:15px; display:inline">[12/2023]&ensp;</p><p style="font-size:20px; display:inline">New Article on Scientific Report Journal</p> -->
  <p style="font-size:15px; display:inline">[12/2023] - </p>
  <p style="font-size:20px; display:inline">New Article on Scientific Report Journal</p>
  <!-- <h4>12/2023 - New Article on Scientific Report Journal</h4> -->

  <p>Our article <a href="https://www.nature.com/articles/s41598-023-49571-7">“A mirror therapy system using virtual reality and an actuated exoskeleton for the recovery of hand motor impairments: a study of acceptability, usability, and embodiment”</a> has been published on Scientific Report journal.<br /></p>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/znBTWJ_E1Bc?si=aQG9c56uld6US3aU" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

  <!-- <p style="font-size:15px; display:inline">[12/2023]&ensp;</p><p style="font-size:20px; display:inline">New RA-L Article</p> -->
  <p style="font-size:15px; display:inline">[12/2023] - </p>
  <p style="font-size:20px; display:inline">New RA-L Article</p>
  <!-- <h4>12/2023 - New RA-L Article</h4> -->

  <p>Our article <a href="https://ieeexplore.ieee.org/document/10380668">“A Sim-to-Real Deep Learning-based Framework for Autonomous Nano-drone Racing”</a> has been published on the IEEE Robotics and Automation Letters (RA-L) journal.<br /></p>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/vHTAwUsj-nk?si=ZfypS0slXRanSF59" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

  <!-- <p style="font-size:15px; display:inline">[11/2023]&ensp;</p><p style="font-size:20px; display:inline">"Quality of Life" Label!</p> -->
  <p style="font-size:15px; display:inline">[11/2023] - </p>
  <p style="font-size:20px; display:inline">“Quality of Life” Label!</p>
  <!-- <h4>11/2023 - "Quality of Life" Label!</h4> -->

  <div class="row">
    <div class="col-8">
      <p> Our project “Remotely-assisted Enhanced Mirror Therapy (REMiT)” has been awarded with the “Quality of Life” label from the <a href="https://dallemolle.ch/concours-2023-ceremonie-de-remise-des-prix/">Fondation Dalle Molle</a>. With the VRHEM project we developed a system leveraging VR technology and a hand exoskeleton (provided by <a href="https://emovocare.com">emovo</a>) to enahance traditional Mirror Therapy.<br /> With REMiT we build on top of this to unlock telemedicine features: we allow therapists to remotely connect with their patients and supervise the therapy session. </p>
    </div>
    <div class="col-4">
      <p> <a href="images/dalle_molle.jpg"><img src="images/dalle_molle.jpg" width="100%" /></a> </p>
    </div>
  </div>

  <!-- <p style="font-size:15px; display:inline">[11/2023]&ensp;</p><p style="font-size:20px; display:inline">New RAS Article</p> -->
  <p style="font-size:15px; display:inline">[11/2023] - </p>
  <p style="font-size:20px; display:inline">New RAS Article</p>
  <!-- <h4>11/2023 - New RAS Article</h4> -->

  <p>Our article <a href="https://www.sciencedirect.com/science/article/pii/S0921889023002075">“Self-Supervised Prediction of the Intention to Interact with a Service Robot”</a> has been published on the Robotics and Autonomous Systems (RAS) journal.<br /></p>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/mdZDIsr5tcU?si=fGOjIB3kUkCA1SmP" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

  <!-- <p style="font-size:15px; display:inline">[11/2022]&ensp;</p><p style="font-size:20px; display:inline">Demo Deployed at Swiss Robotics Days 2022</p> -->
  <p style="font-size:15px; display:inline">[11/2022] - </p>
  <p style="font-size:20px; display:inline">Demo Deployed at Swiss Robotics Days 2022</p>
  <!-- <h4>11/2022 - Demo Deployed at Swiss Robotics Days 2022</h4> -->

  <div class="row">
    <div class="col-6">
      <p> <a href="images/srd2022.jpeg"><img src="images/srd2022.jpeg" width="100%" /></a> </p>
    </div>
    <div class="col-6">
      <p>We were pretty busy during the Swiss Robotics Days 2022. Hundreds of people visited our boot to try our demo. Its ease of use made it accessible and funny even for children :D <br /> Check our <a href="https://idsia-robotics.github.io/pointing/">research on pointing based interactions</a>! </p>
    </div>
  </div>

  <!-- <p style="font-size:15px; display:inline">[09/2022]&ensp;</p><p style="font-size:20px; display:inline">Nanocopter AI Challenge at IMAV22</p> -->
  <p style="font-size:15px; display:inline">[09/2022] - </p>
  <p style="font-size:20px; display:inline">Nanocopter AI Challenge at IMAV22</p>
  <!-- <h4>09/2022 - Nanocopter AI Challenge at IMAV22</h4> -->

  <p>Our team won the 1st Nanocopter AI Challenge which took place at IMAV2022 in Delft.</p>
  <div class="row">
    <div class="col-8">
      <p> <a href="images/imav_team.jpeg"><img src="images/imav_team.jpeg" width="89%" /></a> </p>
    </div>
    <div class="col-4">
      <p> <a href="images/imav_certificate.jpg"><img src="images/imav_certificate.jpg" width="100%" /></a> </p>
    </div>
  </div>

  <!-- <p style="font-size:15px; display:inline">[06/2022]&ensp;</p><p style="font-size:20px; display:inline">Innosuisse grant for VRHEM</p> -->
  <p style="font-size:15px; display:inline">[06/2022] - </p>
  <p style="font-size:20px; display:inline">Innosuisse grant for VRHEM</p>
  <!-- <h4>06/2022 - Innosuisse grant for VRHEM</h4> -->

  <p>Our project titled “Virtual Reality and Hand Exoskeleton for Mirror Therapy: a Feasibility Study (VRHEM)” has been granted by <a href="https://www.aramis.admin.ch/Grunddaten/?ProjectID=51064&amp;Sprache=en-US">Innosuisse - Swiss Innovation Agency</a></p>

  <!-- <p style="font-size:15px; display:inline">[06/2022]&ensp;</p><p style="font-size:20px; display:inline">Publication at CASE 2022</p> -->
  <p style="font-size:15px; display:inline">[06/2022] - </p>
  <p style="font-size:20px; display:inline">Publication at CASE 2022</p>
  <!-- <h4>06/2022 - Publication at CASE 2022</h4> -->

  <p>Our paper <a href="https://ieeexplore.ieee.org/document/9926448">“Selecting Objects on Conveyor Belts Using Pointing Gestures Sensed by a Wrist-worn Inertial Measurement Unit”</a> will be published at the 2022 IEEE 18th International Conference on Automation Science and Engineering (CASE).<br /></p>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/fEnPEXPlVIM?si=lHzBq80DMtjIOXb7" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

  <!-- <p style="font-size:15px; display:inline">[05/2022]&ensp;</p><p style="font-size:20px; display:inline">Publication at CIRP 2022</p> -->
  <p style="font-size:15px; display:inline">[05/2022] - </p>
  <p style="font-size:20px; display:inline">Publication at CIRP 2022</p>
  <!-- <h4>05/2022 - Publication at CIRP 2022</h4> -->

  <p>Our paper <a href="https://www.sciencedirect.com/science/article/pii/S221282712200395X">Towards the integration of a pointing-based human-machine interface in an industrial control system compliant with the IEC 61499 standard”</a> will be published in the Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022.<br /></p>

  <!-- <p style="font-size:15px; display:inline">[01/2022]&ensp;</p><p style="font-size:20px; display:inline">Publications at HRI 2022</p> -->
  <p style="font-size:15px; display:inline">[01/2022] - </p>
  <p style="font-size:20px; display:inline">Publications at HRI 2022</p>
  <!-- <h4>01/2022 - Publications at HRI 2022</h4> -->

  <p>Our works <a href="https://ieeexplore.ieee.org/abstract/document/9889380">“Interacting with a Conveyor Belt in Virtual Reality using Pointing Gestures”</a> and <a href="https://ieeexplore.ieee.org/document/9889486">“PointIt: A ROS Toolkit for Interacting with Co-located Robots using Pointing Gestures”</a> (code <a href="https://github.com/Gabry993/pointing-user-interface-hri"> here</a>) will be published at the 17th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI 2022). <video width="100%" controls=""> <source src="https://idsia-robotics.github.io/pointing/files/videos/guzzi2022demo.mp4" type="video/mp4" /> </video> </p>

  <!-- <p style="font-size:15px; display:inline">[10/2021]&ensp;</p><p style="font-size:20px; display:inline">New PLR Article</p> -->
  <p style="font-size:15px; display:inline">[10/2021] - </p>
  <p style="font-size:20px; display:inline">New PLR Article</p>
  <!-- <h4>10/2021 - New PLR Article</h4> -->

  <p>Our article <a href="https://www.sciencedirect.com/science/article/pii/S0167865521001938">“Semantic segmentation on Swiss3DCities: A benchmark study on aerial photogrammetric 3D pointcloud dataset”</a> has been published on the Pattern Recognition Letters (PRL) journal. This is the result of the collaboration we had with <a href="https://nomoko.world">Nomoko</a>. Check my related <a href="https://github.com/idsia-robotics/RandLA-Net-pytorch">implementation of a 3D Point Cloud Segmentation model</a>.</p>

  <!-- <p style="font-size:15px; display:inline">[03/2021]&ensp;</p><p style="font-size:20px; display:inline">Publication at ICRA 2021</p> -->
  <p style="font-size:15px; display:inline">[03/2021] - </p>
  <p style="font-size:20px; display:inline">Publication at ICRA 2021</p>
  <!-- <h4>03/2021 - Publication at ICRA 2021</h4> -->

  <p>Our paper <a href="https://ieeexplore.ieee.org/abstract/document/9561387">“Pointing at Moving Robots: Detecting Events from Wrist IMU Data”</a> will be published at the 2021 IEEE International Conference on Robotics and Automation (ICRA).<br /></p>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/-Eroidxx9sY?si=MuZBG5ogLqvOBzMR" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

  <!-- <p style="font-size:15px; display:inline">[09/2019]&ensp;</p><p style="font-size:20px; display:inline">NeuralRope#1 is Live</p> -->
  <p style="font-size:15px; display:inline">[09/2019] - </p>
  <p style="font-size:20px; display:inline">NeuralRope#1 is Live</p>
  <!-- <h4>09/2019 - NeuralRope#1 is Live</h4> -->

  <p><a href="https://www.rsi.ch/info/cultura-e-spettacoli/Il-tunnel-di-Besso-pensa--1169575.html"> The art installation</a> featuring a neural network (implemented by my colleagues and me) running live at the Besso’s tunnel in Lugano is now open. <a href="images/neuralrope.jpeg"><img src="images/neuralrope.jpeg" width="100%" /></a></p>

  <!-- <p style="font-size:15px; display:inline">[05/2019]&ensp;</p><p style="font-size:20px; display:inline">Publication at ICRA 2019</p> -->
  <p style="font-size:15px; display:inline">[05/2019] - </p>
  <p style="font-size:20px; display:inline">Publication at ICRA 2019</p>
  <!-- <h4>05/2019 - Publication at ICRA 2019</h4> -->

  <p>Our paper <a href="https://ieeexplore.ieee.org/abstract/document/8794399">“Proximity Human-Robot Interaction Using Pointing Gestures and a Wrist-mounted IMU”</a> will be published at the 2019 International Conference on Robotics and Automation (ICRA).<br /></p>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/hyh_5A4RXZY?si=xuS6a3kDmr2P30ZZ" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

  <!-- <p style="font-size:15px; display:inline">[03/2019]&ensp;</p><p style="font-size:20px; display:inline">Best Video Award at HRI 2019</p> -->
  <p style="font-size:15px; display:inline">[03/2019] - </p>
  <p style="font-size:20px; display:inline">Best Video Award at HRI 2019</p>
  <!-- <h4>03/2019 - Best Video Award at HRI 2019</h4> -->

  <div class="row">
    <div class="col-4">
      <p> <a href="images/hri2019_award.jpg"><img src="images/hri2019_award.jpg" width="100%" /></a> </p>
    </div>
    <div class="col-8">
      <p> Our video <a href="https://ieeexplore.ieee.org/abstract/document/8673020">“Pointing Gestures for Proximity Interaction”</a> got the Best Video Award at the 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI2019). You can find related research <a href="https://idsia-robotics.github.io/pointing/pointing-gestures/index.html">here</a>. </p>
    </div>
  </div>
  <div class="embed-responsive embed-responsive-16by9">
    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/yafy-HZMk_U?si=zznAOIOe3zkrJgMj" allowfullscreen=""></iframe>
  </div>
  <p><br /></p>

</div>

</div>

      </div>
    </div>

    <br/>
<section id="footer">
<div class="container-footer">
  <div class="panel-footer">
	  <div class="row">
		<div class="col-sm-4">
		    <h5>About</h5>	
            <p>Gabriele Abbate<br/> Research/Software Engineer<br/> Istituto Dalle Molle di Studi sull'Intelligenza Artificiale (IDSIA) </br>USI-SUPSI
</p>
		</div>

		<div class="col-sm-4">
		    <h5>Contact</h5>	
            <p><a href="#" target="_blank" data-gen-agar><i class="fa fa-envelope fa-1x"></i> Contact Gabriele via email</a> <br/>
</p>
		</div>

		<div class="col-sm-4">
		    <h5>Coordinates</h5>	
            <p>University Campus USI-SUPSI<br/> Via la Santa 1, Lugano<br/> 6900, Switzerland
</p>
		</div>
	  </div>

      <center><p>&copy 2024 Gabriele Abbate </p></center>
	</div>
  </div>
</div>

<script src="/assets/javascript/bootstrap/jquery.min.js"></script>
<script src="/assets/javascript/bootstrap/bootstrap.bundle.min.js"></script>
<script src="/assets/javascript/agar_hide.js"></script>


  </body>

</html>
